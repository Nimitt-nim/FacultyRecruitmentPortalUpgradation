{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Journal Name and Authors From DOI number\n",
    "\n",
    "import requests\n",
    "def get_journal_and_authors_from_doi(doi):\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            journal_name = data['message']['container-title'][0]  \n",
    "            authors = data['message']['author']\n",
    "            author_names = [f\"{author['given']} {author['family']}\" for author in authors]\n",
    "            return journal_name, author_names\n",
    "        else:\n",
    "            print(f\"Error 2. Status code: {response.status_code}\")\n",
    "    except:\n",
    "        print(\"Error 1.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Link of Journal Data page from main ScimagoJR page\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def search_page(journal_name):\n",
    "  search_name=journal_name.strip().replace(\" \",\"+\")\n",
    "  search_name=search_name.replace(':','%3A')\n",
    "  search_url=f\"https://www.scimagojr.com/journalsearch.php?q={search_name}\"\n",
    "  r = requests.get(search_url)\n",
    "  if r.status_code==200:\n",
    "    soup = BeautifulSoup(r.content, 'html5lib')\n",
    "    try:\n",
    "      search_result=soup.find('div',class_=\"search_results\").find(\"a\")['href']\n",
    "    except TypeError:\n",
    "      search_result=None\n",
    "      print(journal_name,\"No results were found\")\n",
    "  else:\n",
    "    search_result=None\n",
    "    print(journal_name,'Page not found 0')\n",
    "  return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Quartile from Journal Data\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def quartile_list(search_result):\n",
    "    if search_result is not None:\n",
    "        result_url = f'https://www.scimagojr.com/{search_result}'\n",
    "        try:\n",
    "            response = requests.get(result_url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            quartile_th = soup.find('th', text='Quartile')\n",
    "            if quartile_th:\n",
    "                quartile_table = quartile_th.find_parent('table')\n",
    "                if quartile_table:\n",
    "                    df = pd.read_html(str(quartile_table), match='Quartile')[0]\n",
    "                    latest_rating_indices = df.groupby('Category').Year.agg('idxmax')\n",
    "                    latest_ratings = df.loc[latest_rating_indices]\n",
    "                    unique_ratings = latest_ratings['Quartile'].unique()[0]\n",
    "                else:\n",
    "                    unique_ratings = None\n",
    "                    print(result_url, \"No quartile category found\")\n",
    "            else:\n",
    "                unique_ratings = None\n",
    "                print(result_url, \"No quartile found on page\")\n",
    "        except ValueError:\n",
    "            unique_ratings = None\n",
    "        except requests.HTTPError:\n",
    "            unique_ratings = None\n",
    "            print(\"Page Not Found\")\n",
    "    else:\n",
    "        unique_ratings = None\n",
    "    return unique_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting DOI data from Google Spreadsheet\n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import numpy as np\n",
    "def get_doi_list_from_spreadsheet(sheetName):\n",
    "    scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name(\"facultyrecruitmentupgradation-5e06eb0edef3.json\", scope)\n",
    "\n",
    "    gc = gspread.authorize(credentials)\n",
    "    worksheet = gc.open(sheetName).sheet1\n",
    "\n",
    "    data = worksheet.get_all_records()\n",
    "    doi_dataframe = pd.DataFrame(data)\n",
    "    doi_check = np.array(doi_dataframe['CATEGORY']).tolist()\n",
    "    doi_done = 0\n",
    "    for i in range(len(doi_check)):\n",
    "        if doi_check[i] != '':\n",
    "            doi_done+=1\n",
    "    doi_data = doi_dataframe['DOI NUMBER']\n",
    "    doi_list = np.array(doi_data).tolist()\n",
    "    doi_list = doi_list[doi_done:]\n",
    "    for i in range(len(doi_list)):\n",
    "        if str(doi_list[i][0:15]) == \"https://doi.org\":\n",
    "            doi_list[i] = doi_list[i][16:]\n",
    "    return doi_list,doi_done\n",
    "sheetName = \"ApplicationsData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Processing Incorrect Entries\n",
    "\n",
    "def post_process_invalid_inputs(Journal_name,doi):\n",
    "    Journal_name = Journal_name.split(':')[0]\n",
    "    return Journal_name,doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing into Google Spreadsheet \n",
    "  \n",
    "def enter_into_sheet(df,sheetName,start):\n",
    "        scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "        credentials = ServiceAccountCredentials.from_json_keyfile_name('facultyrecruitmentupgradation-5e06eb0edef3.json', scope)\n",
    "        gc = gspread.authorize(credentials)\n",
    "        spreadsheet = gc.open(sheetName)\n",
    "\n",
    "        worksheet = spreadsheet.worksheet('Sheet1')  \n",
    "        worksheet.delete_rows(start, start + len(df) -1)\n",
    "        data_sheet = []\n",
    "        n = len(df)\n",
    "        for i in range(n):\n",
    "                data_sheet.append(list(map(str,np.array(df.loc[i]).tolist())))\n",
    "        worksheet.insert_rows(data_sheet, start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Journal name</th>\n",
       "      <th>Category</th>\n",
       "      <th>No of authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1109/ACCESS.2021.3057500</td>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>Q1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           DOI Journal name Category  No of authors\n",
       "0  10.1109/ACCESS.2021.3057500  IEEE Access       Q1              3"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main\n",
    "\n",
    "sheetName = \"ApplicationsData\"\n",
    "doi_list,end = get_doi_list_from_spreadsheet(sheetName)\n",
    "\n",
    "data=[]\n",
    "for doi in doi_list:\n",
    "  journal_name, author_names = get_journal_and_authors_from_doi(doi)\n",
    "  search_result=search_page(journal_name)\n",
    "  quartile=quartile_list(search_result)\n",
    "  if quartile == None:\n",
    "    journal_name = post_process_invalid_inputs(journal_name,doi)[0]\n",
    "  search_result=search_page(journal_name)\n",
    "  quartile=quartile_list(search_result)\n",
    "  data.append([doi,journal_name,quartile,len(author_names)])\n",
    "\n",
    "df=pd.DataFrame(data,columns=['DOI','Journal name','Category','No of authors'])\n",
    "\n",
    "enter_into_sheet(df,sheetName,end+2)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
